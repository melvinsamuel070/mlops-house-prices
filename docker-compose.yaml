# services:
#   backend:
#     build: ./backend
#     image: melvinsamuel070/house-price-backend:latest
#     container_name: backend
#     ports:
#       - "8000:8000"
#     networks:
#       - house_net
#     healthcheck:
#       test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
#       interval: 30s
#       retries: 3

#   frontend:
#     build: ./frontend
#     image: melvinsamuel070/house-price-frontend:latest
#     container_name: frontend
#     ports:
#       - "80:80"
#     depends_on:
#       - backend
#     networks:
#       - house_net

# networks:
#   house_net:
#     driver: bridge



# services:
#   ml-api:
#     build: ./backend
#     image: melvinsamuel070/house-price-backend:mlops
#     container_name: backend
#     ports:
#       - "8000:8000"
#     environment:
#       - ENVIRONMENT=production
#       - MLFLOW_TRACKING_URI=http://mlflow:5000
#     volumes:
#       - ./backend/monitoring:/app/monitoring
#       - ./backend/logs:/app/logs
#     depends_on:
#       - mlflow
#     healthcheck:
#       test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
#       interval: 30s
#       retries: 3
#     networks:
#       - mlops-net

#   ml-frontend:
#     build: ./frontend
#     image: melvinsamuel070/house-price-frontend:mlops
#     container_name: frontend
#     ports:
#       - "80:80"
#     depends_on:
#       - ml-api
#     networks:
#       - mlops-net

#   mlflow:
#     image: python:3.10-slim
#     container_name: mlflow
#     ports:
#       - "5000:5000"
#     working_dir: /mlflow
#     command: >
#       sh -c "
#         pip install --no-cache-dir mlflow==2.14.1 &&
#         mlflow server
#         --backend-store-uri sqlite:///mlflow.db
#         --default-artifact-root /mlruns
#         --host 0.0.0.0
#       "
#     volumes:
#       - ./mlruns:/mlruns
#       - ./mlflow.db:/mlflow.db
#     networks:
#       - mlops-net

# networks:
#   mlops-net:
#     driver: bridge





















# services:
#   ml-api:
#     build: ./backend
#     image: melvinsamuel070/house-price-backend:mlops
#     container_name: backend
#     ports:
#       - "8000:8000"
#     environment:
#       - ENVIRONMENT=production
#       - MLFLOW_TRACKING_URI=http://mlflow:5000
#     volumes:
#       - ./backend/monitoring:/app/monitoring
#       - ./backend/logs:/app/logs
#     depends_on:
#       - mlflow
#     healthcheck:
#       test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
#       interval: 30s
#       retries: 3
#     networks:
#       - mlops-net

#   ml-frontend:
#     build: ./frontend
#     image: melvinsamuel070/house-price-frontend:mlops
#     container_name: frontend
#     ports:
#       - "80:80"
#     depends_on:
#       - ml-api
#     networks:
#       - mlops-net

#   mlflow:
#     build:
#       context: ./mlflow
#       dockerfile: Dockerfile
#     image: melvinsamuel070/mlflow-server:mlops
#     container_name: mlflow
#     ports:
#       - "5000:5000"
#     environment:
#       - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
#       - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlruns
#     volumes:
#       - ./mlflow/mlruns:/mlruns
#       - ./mlflow/mlflow.db:/mlflow.db
#     networks:
#       - mlops-net

# networks:
#   mlops-net:
#     driver: bridge


















services:
  ml-api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: melvinsamuel070/house-price-backend:mlops
    container_name: backend
    ports:
      - "${BACKEND_PORT}:8000"
    env_file:
      - .env
    volumes:
      - ./backend/monitoring:/app/monitoring
      - ./backend/logs:/app/logs
      - ./backend/models:/app/models
    depends_on:
      mlflow:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${BACKEND_PORT}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: always
    networks:
      - mlops-net

  ml-frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: melvinsamuel070/house-price-frontend:mlops
    container_name: frontend
    ports:
      - "${FRONTEND_PORT}:80"
    env_file:
      - .env
    depends_on:
      ml-api:
        condition: service_healthy
    restart: always
    networks:
      - mlops-net

  mlflow:
    build:
      context: ./mlflow
      dockerfile: Dockerfile
    image: melvinsamuel070/mlflow-server:mlops
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlruns
      - MLFLOW_HOST=0.0.0.0
    volumes:
      - ./mlflow/mlruns:/mlruns
      - ./mlflow/mlflow.db:/mlflow.db
    restart: always
    networks:
      - mlops-net

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - mlops-net
    depends_on:
      ml-api:
        condition: service_healthy
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    networks:
      - mlops-net
    depends_on:
      - prometheus
    restart: always

networks:
  mlops-net:
    driver: bridge
